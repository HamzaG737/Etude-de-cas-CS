{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a csv file that contains tweets about covid-19, plus other important informations such as the number of retweets, likes and replies, datetime ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of pickle files\n",
    "n_pickles=27  \n",
    "## The path where the pickles are stored. \n",
    "path='projects/filiere/data'\n",
    "\n",
    "with open(os.path.join(path,'0.pickle'),'rb') as pkl :\n",
    "    sample0=pickle.load(pkl)\n",
    "\n",
    "## save into a dataframe \n",
    "df_all=pd.DataFrame(sample0)\n",
    "for n_pickle in range(1,n_pickles):\n",
    "    with open(os.path.join(path,'{}.pickle'.format(str(n_pickle))),'rb') as pkl :\n",
    "        sample=pickle.load(pkl)\n",
    "    df_all=pd.concat([df_all,pd.DataFrame(sample)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get an idea about the resulted dataframe\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get informations \n",
    "\n",
    "The idea here is to get all possible informations from the HTML file. Unfortunately, it does not contain the location. So\n",
    "to study for instance the french population, we will assume at this point that all french tweets concern French pepole. \n",
    "Nevertheless, we provide another notebook that explores twitter api in order to get users locations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infos(x): \n",
    "    \"\"\"\n",
    "    Function that parses html file using BeautifulSoup in order to get these infos : number of replies, retweets, likes \n",
    "    and if the tweet is a share tweet or not .\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(x, 'html.parser')\n",
    "    date_time=soup.find_all('time')[0].get('datetime')\n",
    "    all_divs=soup.find_all('div')\n",
    "    all_labels=[link.get('aria-label') for link in all_divs]\n",
    "    \n",
    "    replies,retweets,likes,done=None,None,None,False\n",
    "    for x in all_labels :\n",
    "        if x==None :\n",
    "            continue \n",
    "        if done==False and (('like') in x or ('reply') in x or 'Retweet' in x ):\n",
    "            try : \n",
    "                replies=int(re.findall('([0-9]+) repl',x)[0])\n",
    "            except :\n",
    "                replies=0\n",
    "            try : \n",
    "                retweets=int(re.findall('([0-9]+) Retweet',x)[0])\n",
    "            except :\n",
    "                retweets=0 \n",
    "            try : \n",
    "                likes=int(re.findall('([0-9]+) like',x)[0])\n",
    "            except :\n",
    "                likes=0 \n",
    "            done=True\n",
    "        if 'share' in x :\n",
    "            test=True\n",
    "        else : \n",
    "            test=False\n",
    "    return date_time,replies,retweets,likes,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "tabs_add= df_all['html'].progress_apply(lambda x:get_infos(x))  \n",
    "\n",
    "## Convert the data obtained via the parsing into a dataframe\n",
    "df_new = pd.DataFrame(list(tabs_add.values), columns =['datetime', 'replies', 'retweets','likes','is_share']) \n",
    "## Add the columns\n",
    "df_all= pd.concat( [df_all,df_new] ,axis=1)\n",
    "del df_all['html'],df_all['timestamp']\n",
    "\n",
    "## view the five first example with head \n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save into a pickle \n",
    "path_to_save='projects/filiere/saved_data/df_processed.pickle'\n",
    "pickle.dump(df_all,open(path_to_save,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
