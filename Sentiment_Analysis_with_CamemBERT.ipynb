{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Sentiment Analysis with CamemBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a655b841d144a2d9a998595782b6ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba6fd895974c4bfd87790d92ee1c2aef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_600234e31baf49339cf902b196e223f3",
              "IPY_MODEL_7915c13c58c14ca0a95a8fb6e4b40c85"
            ]
          }
        },
        "ba6fd895974c4bfd87790d92ee1c2aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "600234e31baf49339cf902b196e223f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_30e6997b3301460e9fdaa16470ef53a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c23b6c4185e2452d858cf6fe045087e9"
          }
        },
        "7915c13c58c14ca0a95a8fb6e4b40c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a36331c2c524a778a4d1fde4f1ed2a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508/508 [01:04&lt;00:00, 7.86B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28cf25cefc3f4ffdba637e351fd93062"
          }
        },
        "30e6997b3301460e9fdaa16470ef53a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c23b6c4185e2452d858cf6fe045087e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a36331c2c524a778a4d1fde4f1ed2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28cf25cefc3f4ffdba637e351fd93062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f20df76f7da24a67a2c0f969de0e5283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_22e61069f31a4235a421f454753219df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5f2f9873fc84260a33a66d1eb1ab489",
              "IPY_MODEL_a31a9dfb6fa34d069995c5c47e850194"
            ]
          }
        },
        "22e61069f31a4235a421f454753219df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5f2f9873fc84260a33a66d1eb1ab489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8a79b8db56e4375a58a4cb91aa27e4e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b275efb56c324aae85c6bbab5434b14a"
          }
        },
        "a31a9dfb6fa34d069995c5c47e850194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4abe1ed28eca48d7a6b07af215f4312d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:23&lt;00:00, 19.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fbbcca16a6343f3aa376bec1fcdde9d"
          }
        },
        "d8a79b8db56e4375a58a4cb91aa27e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b275efb56c324aae85c6bbab5434b14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4abe1ed28eca48d7a6b07af215f4312d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fbbcca16a6343f3aa376bec1fcdde9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e3735d610854e308ea72206faea526a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af2198c16d174dfc91cdc3ad515f85b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_078474cf3b5e4be997a860a2acc01bcf",
              "IPY_MODEL_fb4eb23e35df41d6830cd9dd34a4dab5"
            ]
          }
        },
        "af2198c16d174dfc91cdc3ad515f85b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "078474cf3b5e4be997a860a2acc01bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e9535300f144a5980837589c777029f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_046aa65aa60047259116a8f7bf3487f1"
          }
        },
        "fb4eb23e35df41d6830cd9dd34a4dab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4fe14da51b142c4bae8dfd5e411688c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [00:22&lt;00:00, 35.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26789b429a99471ca6505d1f538cfba4"
          }
        },
        "3e9535300f144a5980837589c777029f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "046aa65aa60047259116a8f7bf3487f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4fe14da51b142c4bae8dfd5e411688c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26789b429a99471ca6505d1f538cfba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uYx_VX_Nfjp"
      },
      "source": [
        "This notebook is based on the tutorial at https://www.curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLoAJjhkB4K_"
      },
      "source": [
        "# Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad20J53u9psq"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1xflQiMvTvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29f1966-e161-4c5f-d07f-1caf1b3eba7b"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVpFpQSo1k2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408abaa7-2862-4134-a0f6-c2ddde9a4634"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4304f0d8516092f3e21917f981489f19962498d98f95ea5d96f1228aada19a6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "  Found existing installation: sentencepiece 0.1.94\n",
            "    Uninstalling sentencepiece-0.1.94:\n",
            "      Successfully uninstalled sentencepiece-0.1.94\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-cPvyVNa_n"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhWjW0hl0YFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961f0f36-81d7-46cf-ee7b-e249d7749a30"
      },
      "source": [
        "from transformers import CamembertConfig, CamembertTokenizer, CamembertForSequenceClassification\n",
        "\n",
        "# Initializing a configuration\n",
        "configuration = CamembertConfig()\n",
        "print(configuration)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CamembertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"camembert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh5UJEc2VFyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "8a655b841d144a2d9a998595782b6ec0",
            "ba6fd895974c4bfd87790d92ee1c2aef",
            "600234e31baf49339cf902b196e223f3",
            "7915c13c58c14ca0a95a8fb6e4b40c85",
            "30e6997b3301460e9fdaa16470ef53a4",
            "c23b6c4185e2452d858cf6fe045087e9",
            "8a36331c2c524a778a4d1fde4f1ed2a2",
            "28cf25cefc3f4ffdba637e351fd93062",
            "f20df76f7da24a67a2c0f969de0e5283",
            "22e61069f31a4235a421f454753219df",
            "a5f2f9873fc84260a33a66d1eb1ab489",
            "a31a9dfb6fa34d069995c5c47e850194",
            "d8a79b8db56e4375a58a4cb91aa27e4e",
            "b275efb56c324aae85c6bbab5434b14a",
            "4abe1ed28eca48d7a6b07af215f4312d",
            "1fbbcca16a6343f3aa376bec1fcdde9d"
          ]
        },
        "outputId": "c3441654-e715-4721-ae62-d4dbe41e65a8"
      },
      "source": [
        "# Initializing a model from the configuration\n",
        "model = CamembertForSequenceClassification.from_pretrained('camembert-base')\n",
        "# Accessing the model configuration\n",
        "configuration = model.config "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a655b841d144a2d9a998595782b6ec0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f20df76f7da24a67a2c0f969de0e5283",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445032417.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYnGfj5hVMpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987bb9f9-e44a-4509-d28d-cd79af7be893"
      },
      "source": [
        "print(model.classifier)\n",
        "\n",
        "from transformers.modeling_roberta import RobertaClassificationHead\n",
        "\n",
        "class RobertaHeadConfig():\n",
        "  def __init__(self, hidden_size, droupout, num_labels):\n",
        "    self.hidden_size = hidden_size\n",
        "    self.hidden_dropout_prob = droupout\n",
        "    self.num_labels = num_labels\n",
        "  \n",
        "\n",
        "model.classifier = RobertaClassificationHead(config = RobertaHeadConfig(768, 0.1, 3))\n",
        "\n",
        "print(model.classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RobertaClassificationHead(\n",
            "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n",
            "RobertaClassificationHead(\n",
            "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1LhvD35Br7P"
      },
      "source": [
        "# Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crb_C5xwB1Hv"
      },
      "source": [
        "BERT models need a special preprocessing of the data before input. Texts have to be tokenized, to be divided in separate sentences by special tokens and to be padded to a fixed length. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlkSFEcyEDPw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2e3735d610854e308ea72206faea526a",
            "af2198c16d174dfc91cdc3ad515f85b3",
            "078474cf3b5e4be997a860a2acc01bcf",
            "fb4eb23e35df41d6830cd9dd34a4dab5",
            "3e9535300f144a5980837589c777029f",
            "046aa65aa60047259116a8f7bf3487f1",
            "b4fe14da51b142c4bae8dfd5e411688c",
            "26789b429a99471ca6505d1f538cfba4"
          ]
        },
        "outputId": "7ac7bc55-86cb-4e8f-be5b-9ff166a9788b"
      },
      "source": [
        "\n",
        "sample_text = 'Ceci est un test.'\n",
        "\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "\n",
        "def encode_text(text_string):\n",
        "  tensor = tokenizer.encode_plus(\n",
        "  text_string,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=True,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  padding = 'max_length',\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        "  )\n",
        "  return tensor \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e3735d610854e308ea72206faea526a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=810912.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFF_nBrC8b9G"
      },
      "source": [
        "test_data = pd.read_csv('/content/testset_sent.csv')\n",
        "train_data = pd.read_csv('/content/trainset_sent.csv', lineterminator='\\n')\n",
        "\n",
        "test_data_list = []\n",
        "\n",
        "for line in test_data.to_dict('records'):\n",
        "  text = line['text']\n",
        "  pol = line['polarity']\n",
        "  encoded = encode_text(text)\n",
        "  test_data_list += [[encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask'], pol]]\n",
        "\n",
        "test_preprocessed = pd.DataFrame(test_data_list, columns=['input_ids', 'token_type_ids', 'attention_mask', 'polarity'])\n",
        "\n",
        "train_data_list = []\n",
        "\n",
        "for line in train_data.to_dict('records'):\n",
        "  text = line['text']\n",
        "  pol = line['polarity']\n",
        "  encoded = encode_text(text)\n",
        "  train_data_list += [[encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask'], pol]]\n",
        "\n",
        "train_preprocessed = pd.DataFrame(train_data_list, columns=['input_ids', 'token_type_ids', 'attention_mask', 'polarity'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6ioOlPqTFbV"
      },
      "source": [
        "test_preprocessed.to_csv('test_preprocessed.csv')\n",
        "train_preprocessed.to_csv('train_preprocessed.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW6cUb2tFWRi"
      },
      "source": [
        "Creation of a Pytorch dataset object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkmU-sdkGvUp"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "  def __getitem__(self, item):\n",
        "    #text = self.dataframe['text'][item]  not necessary \n",
        "    polarity = self.dataframe['polarity'][item]\n",
        "    input_ids = self.dataframe['input_ids'][item]\n",
        "    token_type_ids = self.dataframe['token_type_ids'][item]\n",
        "    attention_mask = self.dataframe['attention_mask'][item]\n",
        "    return {\n",
        "      #'text': text,\n",
        "      'input_ids': input_ids.flatten(), # flatten ?\n",
        "      'token_type_ids' : token_type_ids.flatten(),\n",
        "      'attention_mask': attention_mask.flatten(),\n",
        "      'targets': torch.tensor(polarity, dtype=torch.long) # targets are the polarity of each tweet\n",
        "    }\n",
        "\n",
        "\n",
        "train_val_dataset = TweetDataset(train_preprocessed)\n",
        "test_dataset = TweetDataset(test_preprocessed)\n",
        "\n",
        "train_dataset, val_dataset = train_test_split(train_val_dataset, test_size=0.2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNBKfGpFF3YV"
      },
      "source": [
        "Then Dataloaders to seperate the data into batches ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrTfQ_uGF8-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695c70ed-bf86-46a3-8c65-a8552f6e9e39"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_dataloader = DataLoader( train_dataset, batch_size=batch_size )\n",
        "val_dataloader = DataLoader( val_dataset, batch_size=batch_size )\n",
        "\n",
        "test_dataloader = DataLoader( test_dataset, batch_size=batch_size )\n",
        "\n",
        "\n",
        "# test of the shapes\n",
        "data = next(iter(train_dataloader))\n",
        "\n",
        "print(data.keys())\n",
        "\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'targets'])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMCI7WF9MveJ"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Js8EkuNBFd"
      },
      "source": [
        "The classifiers are already part of this model, but we could build our own on top of the basic CamemBERT model. \n",
        "\n",
        "From the CamemBERT original paper : \n",
        "\n",
        "We fine-tune independently CamemBERT for each task and each dataset. We optimise the model using the Adam optimiser [38] with a fixed learning rate. We run a grid search on a combination of learning rates and batch sizes. We select the best model on the validation set out of the 30 first epochs.\n",
        "\n",
        "Although this might push the performances even further, for all tasks except NLI, we don’t apply any regularisation techniques such as weight decay, learning rate warm-up or discriminative fine-tuning. We show that fine-tuning CamemBERT in a straight-forward manner leads to state-of-the-art results on most tasks and outperforms the existing BERT-based models in most cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3R4JNzGMz6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21f1678-33f3-4819-a292-8adf30408afb"
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "# decrease weight \n",
        "\n",
        "# moving the model to GPU \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# hyperparameters\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "EPOCHS = 10\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "\n",
        "# training the model for one epoch \n",
        "\n",
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    n_examples ):\n",
        "\n",
        "  model = model.train() # train mode \n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs[0], dim=1)\n",
        "    loss = loss_fn(outputs[0], targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "# evaluating the model for one epoch\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval() # evaluation mode\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs= model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs[0], dim=1)\n",
        "      loss = loss_fn(outputs[0], targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ5si_dvNURN"
      },
      "source": [
        "# training loop : \n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(train_dataset)\n",
        "  )\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_dataloader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(val_dataset)\n",
        "  )\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2fymrnZ6S1b"
      },
      "source": [
        "##Apply on covid tweet data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjzVOLne6Vrf"
      },
      "source": [
        "df_covid = pd.read_csv('df_french_clean.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R9NYoct6fV4"
      },
      "source": [
        "test_data_list = []\n",
        "\n",
        "for line in df_covid.to_dict('records'):\n",
        "  text = line['text']\n",
        "  encoded = encode_text(text)\n",
        "  test_data_list += [[encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask']]]\n",
        "\n",
        "test_covid_preprocessed = pd.DataFrame(test_data_list, columns=['input_ids', 'token_type_ids', 'attention_mask'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dlpg6Wl7n41"
      },
      "source": [
        "class TweetCovidDataset(Dataset):\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "  def __getitem__(self, item):\n",
        "    #text = self.dataframe['text'][item]  not necessary \n",
        "    input_ids = self.dataframe['input_ids'][item]\n",
        "    token_type_ids = self.dataframe['token_type_ids'][item]\n",
        "    attention_mask = self.dataframe['attention_mask'][item]\n",
        "    return {\n",
        "      #'text': text,\n",
        "      'input_ids': input_ids.flatten(), # flatten ?\n",
        "      'token_type_ids' : token_type_ids.flatten(),\n",
        "      'attention_mask': attention_mask.flatten()\n",
        "    }\n",
        "\n",
        "covid_dataset = TweetCovidDataset(test_covid_preprocessed)\n",
        "test_covid_dataloader = DataLoader( covid_dataset, batch_size=batch_size ,shuffle=False )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMyaNCeC_hcd"
      },
      "source": [
        "## model redefine \n",
        "model = CamembertForSequenceClassification.from_pretrained('camembert-base')\n",
        "# Accessing the model configuration\n",
        "configuration = model.config \n",
        "\n",
        "model.classifier = RobertaClassificationHead(config = RobertaHeadConfig(768, 0.1, 3))\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_state_best.bin'))\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXD4iBMN8q34"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def test_model(model, data_loader, device, n_examples):\n",
        "  model = model.eval() # evaluation mode\n",
        "  losses = []\n",
        "  with torch.no_grad():\n",
        "    all_preds,all_probs = [],[]\n",
        "    for d in tqdm(data_loader,total=len(data_loader)):\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      outputs= model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs[0], dim=1)\n",
        "      soft = torch.nn.Softmax(dim=1)\n",
        "      probs = soft (outputs[0])\n",
        "      all_preds+=list(preds.cpu().data.numpy())\n",
        "      all_probs+=list(probs.cpu().data.numpy())\n",
        "  return all_preds, all_probs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNnxokd49ST5",
        "outputId": "e79ebd36-de6e-45c2-a2ff-e284bc039071"
      },
      "source": [
        "all_preds,all_probs = test_model(model, test_covid_dataloader, device, len(covid_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1541/1541 [06:37<00:00,  3.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKniFKp396Do",
        "outputId": "e52c50e6-0f23-48a6-d2ca-2a46b50e5315"
      },
      "source": [
        "df_covid['predictions'] = all_preds\n",
        "df_covid['probs'] = all_probs\n",
        "df_covid.predictions.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6143\n",
              "2    4093\n",
              "1    2089\n",
              "Name: predictions, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eimwnof2B51s",
        "outputId": "6fcbcd8f-5720-427f-8ca8-77583207f36e"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "df_covid[df_covid.predictions == 1].sample(50)['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2773     FOCUS | Grippe, rhume, gastro, mal de gorge  .  .  .   les maladies saisonnières sont de retour .  Cependant, si certains micro-organismes nous rendent malades, d ' autres s ' avèrent bénéfiques à notre santé                                                                                    \n",
              "3353     Coronavirus  :  restez informé et prémunissez-vous contre les fakenews Comment faire la différence entre le coronavirus et la grippe  ?                                                                                                                                                             \n",
              "4534     Après la bronchite, la grippe .  .  Géniale  .  .                                                                                                                                                                                                                                                   \n",
              "3139     Boiron vous recommande son médicament contre la grippe mais précise que  * pas de somnolence induite  * aucune interaction avec d ' autres médicaments  * ne masque aucun symptôme de la grippe Le début d ' une reconnaissance qu ' ils vendent des médicaments qui ne font rien du tout  ?        \n",
              "7555     Coronavirusfr  :  l ' épidémie fait bondir les ventes de \"La peste\" d ' Albert Camus, en France comme Italie  via                                                                                                                                                                                   \n",
              "9861     J-3 semaines avant la conférence  !  Conformément aux directives du gouvernement suite à l ' épidémie de Coronavirus COVID-19, nous vous annonçons que la conférence Symfony_Live Paris 2020 est pour l ' instant maintenue  !  Rendez-vous les 26 et 27 mars                                       \n",
              "8904     En vrai le coronavirus c ' est vraiment pas si grave que ça, sur un humain en bonne santé ça a juste les effets d ' une grippe, en deux semaines de repos et de paracetamol c ' est \" soigné \" , faut arrêter de stresser le monde, et puis les médias en font toujours +                           \n",
              "3911     Je viens d ' écouter en ENTIER Stupid Love elle est trop bien ça a soigné ma grippe                                                                                                                                                                                                                 \n",
              "10508    Ma sœur et ma nièce ont un sacré coup de crayon .  Dessine-moi un virus  !  CoronavirusFrance COVID19france                                                                                                                                                                                         \n",
              "9881     Des ouvriers travaillent dans une entreprise pharmaceutique dans la province chinoise du Yunnan  ( sud-ouest )  .  L ' entreprise a repris sa production le 29 janvier pour assurer l ' approvisionnement médical et soutenir la lutte contre l ' épidémie de nouveau coronavirus . EconomieChinoise\n",
              "11507    Vive la grippe                                                                                                                                                                                                                                                                                      \n",
              "11486    C ' est rendu que le rhume fesse aussi fort que la grippe  .  .  .   Prompt rétablissement  .  .  .   Bonne journée  .  .  .   ; )                                                                                                                                                                  \n",
              "5754     En ce moment, on n ' a pas le droit de se faire la bise ou de se serrer la main  !  Pas grave, à l ' agence, on a trouvé la parade .  Il est bon de rire parfois  .  .  .   CORONAVIRUSENFRANCE, COVID19france                                                                                      \n",
              "4311     \"  .  .  .   je pense que le  ( TOUT )  gouvernement, dont la fonction fondamentale est de protéger le public, pourrait faire plus dans cette situation  .  .  .  \"   .   .  coronavirus covid2019 COVID19france                                                                                    \n",
              "6374     Enfin, oui, sur l ' essentiel, nous sommes bien d ' accord _com  :  le dépistage est crucial pour stopper l ' épidémie VIH .  Le virus continue de se propager, entre autres, car il y a encore 24 000 personnes qui ignorent être séropositives en France à l ' heure actuelle .                   \n",
              "2926     Les épidémies de grippe, gastro et bronchiolite continuent à gagner du terrain sur le territoire français                                                                                                                                                                                           \n",
              "4423     Comment la France se prépare au risque épidémique de coronavirus  ?  COVID19france Lire le document de 42 pages  SVT                                                                                                                                                                                \n",
              "2171     OlivierVéran a déclaré qu ' il n ' y a pas d ' épidémie en France .  Et bien nous sommes tous rassurés ou presque  !  Coronavirus  :  20 nouveaux cas de contamination détectés en France  via lemondefr CoronaVirus COVID19france                                                                  \n",
              "5630     Enfin quelqu ' un qui a vraiment du bon sens et qui parle en tant que professionnel de la santé, respectueux de tous .  Tout le contraire du pathétique M .  Leuba, qui montre son sérieux en disant qu ' à coup de Dafalgan, 3-4 jours et c ' est reparti, comme une simple grippe !               \n",
              "4580     J ' ai survécue à la grippe  !                                                                                                                                                                                                                                                                      \n",
              "4902     ComdeCrise On innove  !  Plein de questions en Guyane sur les épidémies alors on a décidé de répondre en direct ce soir en FacebookLive RV ce soir VeryInfectieux 18 : 00 Cayenne  ( 22 : 00 Paris )  ARSguyane sur Facebook gescrise coronavirus grippe dengue covid19                             \n",
              "8455     Prévention contre le CoronavirusFrance  :  Évitez de serrer des mains et de faire la bise .  Privilégiez des modes de communication plus sains  :  fellation et cunnilingus .  coronavirusfr COVID19 COVID19france coronavirus                                                                      \n",
              "8699     Point précieux sur les perspectives de vaccination contre le coronavirus Covid_19fr COVID19fr coronavirusfr CORONAVIRUSENFRANCE                                                                                                                                                                     \n",
              "8036     RT laReclame \"coronavirusfr  :  LEVENEMENTAsso a alerté les pouvoirs publics sur les risques économiques et sociaux, en matière d ' emplois et de sauvegarde des entreprises, que vont entraîner l ' annulation d ' événements à travers la France .                                                \n",
              "6426     Le Comité de Coordination de lutte contre l ' épidémie à virus Ebola confiant d ' éradiquer cette maladie d ' ici fin février en RDC -                                                                                                                                                              \n",
              "12175    A l ' heure où je vous parle, 325 000 personnes ont la grippe en France contre 212 cas de Coronavirus ce qui représente 0,0001  %  de la population française .  Vu comme ça ça fait tout de suite moins peur .  Arrêtons la psychose CORONAVIRUSENFRANCE CoronaVirusUpdate                         \n",
              "4971     KASAÏ_MBUJI_MAYI_RDC :  Comment fêter bonne année L ' épidemie de la diarrhée rouge a déjà tué 6 détenus,& d ' autres dans un état critique dans la Prison Centrale de MBUJI-MAYI depuis deux semaines . Les droits de l ' homme n ' existent pas dans les prisons en RDC .                         \n",
              "38       Il y a quelques semaines dans l ' emission \"le grand jury\" Agnès Buzyn expliquait que \"le masque bleu n ' apportait aucune protection\"  !  Or les médecins en première ligne face à l ' épidémie ne sont dotés qu ' en \"masque bleu\" car pas de stock stratégique en Ffp2  !  BRAVO COVID19fr       \n",
              "9598     vive la grippe                                                                                                                                                                                                                                                                                      \n",
              "1931     Un groupe dirigeant de la Chine pour la lutte contre le COVID-19 a mis l ' accent jeudi sur l ' application de mesures solides pour prendre soin du personnel médical qui lutte au front contre l ' épidémie du COVID-19 .                                                                          \n",
              "2394     En tout cas en sachant que je n ' ai eu ni dengue ni chikungunya ni zika et encore moins la grippe A .  Quand je marche dans la vallée de l ' ombre de la mort, je ne crains aucun mal, car tu es avec moi                                                                                          \n",
              "3787     super la grippe a carnaval                                                                                                                                                                                                                                                                          \n",
              "919      Si seulement ils auraient fermer les aéroport rien de tous sa seraient arriver  .  .  .   Maintenant j ' ai de l ' espoir pour que le collège m ' envoie un mailCOVID19france                                                                                                                       \n",
              "9199     J ' ecoute une nouvelle serie québecoise, \"epidemie\" .  C ' est un peu l ' equivalant de Grey ' s Anatomy .  C ' est très bien .  Bien meilleure qu\"Au secour de Béatrice\" .                                                                                                                        \n",
              "8110     Stade 2 renforcé Stade 3 on en veut pas On va y aller par étape CoronavirusFrance coronavirusfr COVIDー19                                                                                                                                                                                            \n",
              "5640     Coronavirus  :  une intelligence artificielle avait prévu l ' épidémie .  La société a développé un algorithme qui collecte et analyse plusieurs types de données  :  les actualités internationales, les réseaux de suivi des maladies et les publications officielles                             \n",
              "2875     Coronavirus  :  l ' OIM lance un plan pour aider les pays à faire face à l ' épidémie .  Le plan couvre un   .  .  .                                                                                                                                                                                \n",
              "2334     Une entreprise israélienne aurait trouvé la solution pour enrayer l ' épidémie du coronavirus Revoir le reportage en intégralité                                                                                                                                                                    \n",
              "1468     Le PSG apporte son soutien à la Chine , touché par l ' épidémie du Coronavirus PSGFCGB                                                                                                                                                                                                              \n",
              "2430     Entrainement du jour .  Belles oppositions, sérieux, intensité,   .  .  .   La grippe est partie  ?                                                                                                                                                                                                 \n",
              "3775     Hahaha !  Trop forte la meuf elle esquive la grippe et la gastro like a boss .  Ahaha .  Ahah Haha Ha .    .  .  .   Prochaine fois je ferme ma gueule .                                                                                                                                            \n",
              "10475    Si vous avez des astuces pour que ma fille boive/ mange pendant la grippe et que sa température baisse  ( en plus du doliprane )  je suis preneuse  !  J ' ai tout essayé là  .  .  .   Merci                                                                                                       \n",
              "3264     Y a un remède contre la grippe  ?  Un antibiotique  ?  Je sais qu ' il y a des vaccins au taux de succès relatif d ' une année à l ' autre .  Mais un remède infaillible  ?  ?  Je pense qu ' on fait pareil que le nCov, on gère les symptômes au mieux .                                          \n",
              "6066     Il y a 30 ans  ( déjà  ) , j ' étais malade .  Grippé au fond de mon lit, j ' ai écouté religieusement ce concert diffusé en direct sur  avec les commentaires d '  qui était sur place .  Le début d ' une passion immodérée pour                                                                  \n",
              "197      COVID19france coronavirus TRÈS IMPORTANT .  A lire Le système de santé de l ' Italie déjà soumis à rude épreuve et saturé dans certaines régions Les mesures de distanciation sociale doivent être prise très rapidement en France pour freiner le dévp de l ' épidémie                             \n",
              "9706     Ptn j ' ai la grippe jsuis en train de dead mais au moins j ' ai pas les symptômes du corona et ça c ' est coool                                                                                                                                                                                    \n",
              "3543     \"La fermeture des frontières est une mesure de bon sens qui permet en amont de contrôler les personnes entrant sur notre territoire .  C ' est une mesure nécessaire pour limiter les risques d ' epidemie . \" CoronavirusFrance                                                                    \n",
              "526      Propos rassurant du patron du service des maladies inféctueuses Eric Caume lors de la visite du pdt  :  \"le virus est moins grave qu ' on ne le pensait, c ' est un peu comme la grippe .  Mais il est très infectueux, le problème c ' est le nbre de personnes qui pourrait être infecté\"         \n",
              "8217     À Isiro, Chef-lieu du Haut-Uélé RDC, les activités de la communication des risques s ' intensifient en réponse à l ' épidémie de rougeole .  Ce 21 fév, un briefing à été organisé à l ' intention des médias locaux & de la société civile pour une appropriation efficace par la communauté       \n",
              "9019     Bonjour Twitter .  Ah, l ' air vivifiant de la mer  .  .  .   Instantané d ' une épidémie de sieste à Brighton, sous le regard du grand Martin Parr  .  .  .                                                                                                                                        \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAmA78nHEtLX"
      },
      "source": [
        "df_covid.to_csv('df_covid.csv',index=False)"
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}