{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train='labelled_train_data.csv'\n",
    "df_train=pd.read_csv(path_train)\n",
    "\n",
    "path_test='labelled_test_data.csv'\n",
    "df_test=pd.read_csv(path_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tweets by id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define twitter API \n",
    "\n",
    "consumer_key = \"xxxxxxxx\" \n",
    "consumer_secret = \"xxxxxxxxxx\" \n",
    "access_token = \"xxxxxxxxxxxxxxxxx\" \n",
    "access_token_secret = \"xxxxxxxx\" \n",
    "\n",
    "# authorization of consumer key and consumer secret \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "\n",
    "# set access to user's access key and access secret  \n",
    "auth.set_access_token(access_token, access_token_secret) \n",
    "  \n",
    "# calling the api  \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a3685bcc0647efb377524ea3a5d758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 301\n",
      "Rate limit reached. Sleeping for: 657\n",
      "Rate limit reached. Sleeping for: 663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_text(id_):\n",
    "    try :\n",
    "        tweet=api.get_status(id_)\n",
    "        return tweet.text\n",
    "    except :\n",
    "        return None\n",
    "\n",
    "tab_texts=[]\n",
    "for index,rows in tqdm(df_test.iterrows(),total=len(df_test)) :\n",
    "    tab_texts.append(get_text(rows['id']))\n",
    "    if index%100==0 :\n",
    "        with open('/home/hamza/projects/filiere/saved_data/text_sent_test.pkl','wb') as pkl :\n",
    "            pickle.dump(tab_texts,pkl)\n",
    "with open('/home/hamza/projects/filiere/saved_data/text_sent_test.pkl','wb') as pkl :\n",
    "            pickle.dump(tab_texts,pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add to csv and remove Nones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_texts_train=pickle.load(open('/home/hamza/projects/filiere/saved_data/text_sent_all.pkl','rb'))\n",
    "tab_texts_test=pickle.load(open('/home/hamza/projects/filiere/saved_data/text_sent_test.pkl','rb'))\n",
    "\n",
    "df_train['text']=tab_texts_train\n",
    "df_test['text']=tab_texts_test\n",
    "\n",
    "# Merge\n",
    "\n",
    "df_all=pd.concat([df_train,df_test], ignore_index=True)\n",
    "#print(len(df_all))\n",
    "df_all.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "## categorize polarity \n",
    "df_all.polarity=pd.Categorical(df_all.polarity)\n",
    "df_all.rename(columns={'polarity':'pol_symbol'},inplace=True)\n",
    "\n",
    "dict_map={'=':2,'-':0,'+':1}\n",
    "df_all['polarity']=df_all.pol_symbol.map(dict_map)\n",
    "del df_all['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import clean \n",
    "df_all['text']=df_all.text.apply(lambda x:clean.clean(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### separate train test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(df_all, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.reset_index(inplace=True,drop=True)\n",
    "testset.reset_index(inplace=True,drop=True)\n",
    "\n",
    "trainset.to_csv('/home/hamza/projects/filiere/etude_de_cas/data/trainset_sent.csv',index=False)\n",
    "testset.to_csv('/home/hamza/projects/filiere/etude_de_cas/data/testset_sent.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
